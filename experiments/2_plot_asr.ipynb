{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from bon.utils import utils\n",
    "from bon.utils.plot_utils import set_plot_style\n",
    "from bon.utils.power_law_simple import fit_power_law\n",
    "from bon.utils.powerlaw_plot_utils import adjust_color, plot_fitted_asr, plot_mean_and_std\n",
    "from bon.utils.shotgun_utils import calculate_asr_trajectories, process_powerlaw_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = set_plot_style()\n",
    "\n",
    "def convert_to_percentages(data):\n",
    "    return [[value * 100 for value in sublist] for sublist in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/bon-jailbreaking/bon/utils/utils.py:479: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(input_file, lines=True)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/direct_request.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/bon-jailbreaking/bon/utils/utils.py:479\u001b[0m, in \u001b[0;36mload_jsonl_df\u001b[0;34m(input_file)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/bon/lib/python3.11/site-packages/pandas/io/json/_json.py:815\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/bon/lib/python3.11/site-packages/pandas/io/json/_json.py:1023\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         data_lines \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1023\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/bon/lib/python3.11/site-packages/pandas/io/json/_json.py:1051\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1051\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/bon/lib/python3.11/site-packages/pandas/io/json/_json.py:1187\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/bon/lib/python3.11/site-packages/pandas/io/json/_json.py:1403\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1403\u001b[0m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m     )\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m direct_requests \u001b[38;5;241m=\u001b[39m  Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/direct_request.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df_direct \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_jsonl_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirect_requests\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bon-jailbreaking/bon/utils/utils.py:485\u001b[0m, in \u001b[0;36mload_jsonl_df\u001b[0;34m(input_file)\u001b[0m\n\u001b[1;32m    482\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Open the JSONL file and read line by line\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m    487\u001b[0m         \u001b[38;5;66;03m# Parse the JSON object from each line\u001b[39;00m\n\u001b[1;32m    488\u001b[0m         json_obj \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line\u001b[38;5;241m.\u001b[39mstrip())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/direct_request.jsonl'"
     ]
    }
   ],
   "source": [
    "direct_requests =  Path(\"./data/direct_request.jsonl\")\n",
    "df_direct = utils.load_jsonl_df(direct_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_powerlaw_data(models, shotgun_type=\"text\", num_steps=8, train_split=1000, num_concurrent_k=10):\n",
    "    dfs = {}\n",
    "    asrs = {}\n",
    "    train_asrs = {}\n",
    "    perc_asrs = {}\n",
    "\n",
    "    for model_name, model_path in models.items():\n",
    "\n",
    "        print(f\"\\nProcessing {model_name}\")\n",
    "                \n",
    "        dfs[model_name] = process_powerlaw_data(\n",
    "            model_path, df_direct, \n",
    "            \"direct_request_search_steps.jsonl\",\n",
    "            num_steps, num_concurrent_k, 159, shotgun_type=shotgun_type, \n",
    "            pad_to_n_steps=False, overwrite=False,\n",
    "        )\n",
    "        \n",
    "        asrs[model_name] = calculate_asr_trajectories(\n",
    "            dfs[model_name], model_path, num_repeats=10\n",
    "        )\n",
    "        train_asrs[model_name] = calculate_asr_trajectories(\n",
    "            dfs[model_name], model_path, num_repeats=10, train_num_samples=train_split, num_samples=train_split\n",
    "        )\n",
    "        \n",
    "        perc_asrs[model_name] = convert_to_percentages(asrs[model_name])\n",
    "    \n",
    "    experiments = {\n",
    "        model_name: (perc_asrs[model_name], asrs[model_name], train_asrs[model_name], train_asrs[model_name], dfs[model_name])\n",
    "        for model_name in models.keys()\n",
    "    }\n",
    "    \n",
    "    return experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_text = Path(\"./exp/bon/text\")\n",
    "# root_dir_audio = Path(\"./exp/bon/audio\")\n",
    "# root_dir_image = Path(\"./exp/bon/image\")\n",
    "\n",
    "text_models = {\n",
    "    \"GPT-4o-Mini\": root_dir_text / \"gpt-4o-mini\",\n",
    "}\n",
    "\n",
    "audio_models = {\n",
    "    \"Gemini Flash\": root_dir_audio / \"gemini-1.5-flash-001\",\n",
    "}\n",
    "\n",
    "vision_models = {\n",
    "    \"GPT-4o-Mini\": root_dir_image / \"gpt-4o-mini\",\n",
    "}\n",
    "\n",
    "text_experiments = get_powerlaw_data(text_models, shotgun_type=\"text\", num_steps=8)\n",
    "vision_experiments = get_powerlaw_data(vision_models, shotgun_type=\"image\", num_steps=8)\n",
    "audio_experiments = get_powerlaw_data(audio_models, shotgun_type=\"audio\", num_steps=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapping = {\n",
    "    \"Claude 3 Opus\": adjust_color(color_palette[0], 0.5),\n",
    "    \"Claude 3.5 Sonnet\": adjust_color(color_palette[0], -0.1),\n",
    "    \"GPT-4o\": adjust_color(color_palette[2], -0.1),\n",
    "    \"GPT-4o-Mini\": adjust_color(color_palette[2], 0.5),\n",
    "    \"Gemini Flash\": adjust_color(color_palette[3], 0.5),\n",
    "    \"Gemini Pro\": adjust_color(color_palette[3], -0.1),\n",
    "    \"Llama3 8B\": color_palette[6],\n",
    "    \"Circuit Breaking\": color_palette[4],\n",
    "    \"DiVA\": color_palette[8],\n",
    "    \"Cygnet\": color_palette[5],\n",
    "    \"Cygnet w/ system prompt\": color_palette[5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mega Figure 1 Simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models_to_plot = [\"GPT-4o-Mini\", \"Gemini Flash\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(5.5, 2.5), dpi=600)\n",
    "\n",
    "all_asrs = []\n",
    "for i, (modality_exp, modality_name) in enumerate(zip([text_experiments, vision_experiments, audio_experiments], [\"Text\", \"Vision\", \"Audio\"])):\n",
    "    for j, (exp_name, asrs) in enumerate(modality_exp.items()):\n",
    "        if exp_name not in models_to_plot:\n",
    "            continue\n",
    "\n",
    "        # Prepare the data\n",
    "        prop_asr = np.array(asrs[1])\n",
    "        prop_asr_mean = np.mean(prop_asr, axis=0)\n",
    "        prop_asr_std = np.std(prop_asr, axis=0)\n",
    "\n",
    "        perc_asr = np.array(asrs[0])\n",
    "        perc_asr_mean = np.mean(perc_asr, axis=0)\n",
    "        perc_asr_std = np.std(perc_asr, axis=0)\n",
    "\n",
    "        steps = np.arange(1, len(prop_asr_mean)+1)\n",
    "        color = color_mapping[exp_name]\n",
    "\n",
    "        linewidth = 1.15\n",
    "\n",
    "        # Plot regular fit in top row\n",
    "        plot_mean_and_std(axes[i], perc_asr_mean, perc_asr_std, steps, exp_name=\"\", log_scale_x=False, log_scale_y=False, color=color, plot_std_err=True, linewidth=linewidth)\n",
    "\n",
    "        print(f\"Fitting {exp_name}, {modality_name}, final ASR: {perc_asr_mean[-1]:.2f}%, num steps: {len(steps)}\")\n",
    "        all_asrs.append(perc_asr_mean[-1])\n",
    "\n",
    "    \n",
    "    # Set properties for regular fit (top row)\n",
    "    ax = axes[i]\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"ASR (%)\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_title(modality_name)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    # ax.set_yticks([0, 20, 40, 60, 80, 100], [0, 20, 40, 60, 80, 100])\n",
    "    # if i != 0:\n",
    "    #     ax.set_xticks([0, 2000, 4000, 6000], [\"0\", \"2k\", \"4k\", \"6k\"])\n",
    "    # else:\n",
    "    #     ax.set_xticks([0, 2500, 5000, 7500, 10000], [0, \"2.5k\", \"5k\", \"7.5k\", \"10k\"])\n",
    "    # ax.set_xlim(right=7200 if i > 0 else 10000)\n",
    "    # ax.set_ylim(0, 102)\n",
    "    ax.set_xlabel(\"N\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add legend elements\n",
    "legend_elements = []\n",
    "for exp_name, color in color_mapping.items():\n",
    "    if exp_name in models_to_plot:\n",
    "        legend_elements.append(Line2D([0], [0], color=color, linestyle=\"-\", lw=1, label=f\"{exp_name}\"))\n",
    "\n",
    "# Create a single legend below the plots\n",
    "fig.legend(handles=legend_elements, \n",
    "           loc='lower center', \n",
    "           ncol=4, \n",
    "           bbox_to_anchor=(0.52, -0.05),\n",
    "           columnspacing=1,\n",
    "           handlelength=1.5,\n",
    "           handletextpad=0.5,\n",
    "           borderpad=0.5,\n",
    "           labelspacing=0.5)\n",
    "\n",
    "plt.subplots_adjust(bottom=0.28)  # Increased bottom margin\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(np.mean(all_asrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Power Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(5.5, 2.5), dpi=600, sharey=True)\n",
    "\n",
    "models_to_plot = [\"GPT-4o-Mini\", \"Gemini Flash\"]\n",
    "\n",
    "for i, (modality_exp, modality_name) in enumerate(zip([text_experiments, vision_experiments, audio_experiments], [\"Text\", \"Vision\", \"Audio\"])):\n",
    "    ax = axes[i]\n",
    "    for j, (exp_name, asrs) in enumerate(modality_exp.items()):\n",
    "        if exp_name not in models_to_plot:\n",
    "            continue\n",
    "        print(f\"Fitting {exp_name}\")\n",
    "\n",
    "        # Prepare the data\n",
    "        prop_asr = np.array(asrs[1])\n",
    "        prop_asr_mean = np.mean(prop_asr, axis=0)\n",
    "        prop_asr_std = np.std(prop_asr, axis=0)\n",
    "\n",
    "        perc_asr = np.array(asrs[0])\n",
    "        perc_asr_mean = np.mean(perc_asr, axis=0)\n",
    "        perc_asr_std = np.std(perc_asr, axis=0)\n",
    "\n",
    "        steps = np.arange(1, len(prop_asr_mean)+1)\n",
    "        color = color_mapping[exp_name]\n",
    "\n",
    "        linewidth = 1.15\n",
    "        \n",
    "        # Plot log space fit\n",
    "        plot_mean_and_std(ax, prop_asr_mean, prop_asr_std, steps, exp_name=\"\", log_scale_x=True, log_scale_y=True, color=color, plot_std_err=True, linewidth=linewidth, std_scale_factor=1, use_line=False)\n",
    "\n",
    "        # Fit the model\n",
    "        try:\n",
    "            params = fit_power_law(x=steps, y=prop_asr, fit_type=\"linear_log_spacing\", skip_first_points=5)\n",
    "        except Exception:\n",
    "            params = fit_power_law(x=steps, y=prop_asr, fit_type=\"linear\", skip_first_points=5)\n",
    "        \n",
    "        # Plot fitted ASR for log space fit\n",
    "        plot_fitted_asr(ax, steps, params, color=color, exp_name=\"\", log_scale_x=True, log_scale_y=True,linewidth=linewidth)\n",
    "\n",
    "        print(f\"{exp_name}, {modality_name}, {params}\")\n",
    "\n",
    "    # Create second y-axis for ASR percentage\n",
    "    if i == 2:\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_yscale('log')\n",
    "        # ax2.set_ylim(0.03, 5)\n",
    "\n",
    "        # Set ticks for both axes\n",
    "        yticks = ax.get_yticks()\n",
    "        ax.set_yticklabels([f\"{y:.1f}\" for y in yticks])\n",
    "        ax2.set_yticklabels([f\"{np.exp(-y)*100:.0f}%\" for y in yticks])\n",
    "\n",
    "        # Set titles and labels\n",
    "        ax2.set_ylabel(\"ASR (%)\")\n",
    "        ax2.tick_params(axis='both', which='major')\n",
    "        \n",
    "\n",
    "    ax.set_title(modality_name)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"-log(ASR)\")\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    # ax.set_yticks([0.01, 0.1, 1], [0.01, 0.1, 1])\n",
    "    if i == 1:\n",
    "        ax.set_xlabel(\"N\")\n",
    "    # ax.set_xlim(left=10)\n",
    "    # ax.set_xlim(right=7200)\n",
    "    \n",
    "    ax.set_ylim(0.03, 5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add legend elements\n",
    "legend_elements = []\n",
    "for exp_name, color in color_mapping.items():\n",
    "    if exp_name in models_to_plot:\n",
    "        legend_elements.append(Line2D([0], [0], color=color, linestyle=\"-\", lw=1, label=f\"{exp_name}\"))\n",
    "\n",
    "# Create a single legend below the plots\n",
    "fig.legend(handles=legend_elements, \n",
    "           loc='lower center', \n",
    "           ncol=4, \n",
    "           bbox_to_anchor=(0.52, -0.05),  # Moved up slightly\n",
    "           columnspacing=1,\n",
    "           handlelength=1.5,\n",
    "           handletextpad=0.5,\n",
    "           borderpad=0.5,\n",
    "           labelspacing=0.5)  # Reduced font size slightly\n",
    "\n",
    "\n",
    "plt.subplots_adjust(bottom=0.28)  # Increased bottom margin\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
